
Steps for Setting Up and Executing the Facial Recognition System

1. Selecting the Platforms:
   - Choose the development environment and platform based on compatibility with the libraries and frameworks required. For this project, we considered:
     - Jupyter Notebook: Suitable for interactive development and testing.
     - Google Colab: Provides free GPU resources but lacks direct support for webcam integration.
     - Final Decision: Jupyter Notebook on local machine, due to direct hardware access and better library support.

2. Installation of Required Libraries:
   - Ensure that Python is installed on the system. Recommended version: Python 3.7 or above.
   - Install necessary libraries using pip:

     ```
     pip install numpy
     pip install opencv-python
     pip install dlib
     pip install mysql-connector-python
     pip install scipy
     ```

   - Installing Dlib:
     - Dlib requires additional dependencies. Make sure CMake and a compatible C++ compiler are installed.
     - For Windows, install Visual Studio with Desktop development C++.

   - Download Pre-trained Models:
     - Download the following models and place them in the working directory:
       - `shape_predictor_68_face_landmarks.dat`
       - `dlib_face_recognition_resnet_model_v1.dat`

3. Setting Up the Database:
   - Install MySQL and create a database:
     - Database Name: `school_database`
     - Table Name: `students`
     - Columns:
       1. `student_id` (INT, Primary Key, Auto Increment)
       2. `student_name` (VARCHAR)
       3. `student_embeddings` (BLOB)
     - Add additional columns as required.

4. Execution of the Code:
   - Import necessary libraries:

     ```python
     import mysql.connector
     import pickle
     import numpy as np
     import dlib
     import cv2
     from scipy.spatial.distance import cosine
     ```

   - Connect to the MySQL database:

     ```python
     conn = mysql.connector.connect(
         host="localhost",
         user="root",
         password="YourPassword",
         database="school_database"
     )
     cursor = conn.cursor()
     ```

   - Initialize Dlib's face detector and shape predictor:

     ```python
     face_detector = dlib.get_frontal_face_detector()
     shape_predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")
     face_recognizer = dlib.face_recognition_model_v1("dlib_face_recognition_resnet_model_v1.dat")
     ```

   - Function to get face embeddings from the database:

     ```python
     def get_embeddings_from_db():
         cursor.execute("SELECT student_id, student_name, student_embeddings FROM students")
         results = cursor.fetchall()
         
         embeddings_dict = {}
         for student_id, student_name, embeddings_blob in results:
             student_embeddings = pickle.loads(embeddings_blob)
             embeddings_dict[student_id] = {
                 'name': student_name,
                 'embedding': np.array(student_embeddings)
             }
         return embeddings_dict
     ```

   - Capture face using webcam:

     ```python
     def capture_face():
         cap = cv2.VideoCapture(0)
         while True:
             ret, frame = cap.read()
             if not ret:
                 print("Failed to grab frame")
                 break

             faces = face_detector(frame)
             if len(faces) > 0:
                 face = faces[0]
                 face_embedding = get_face_embedding(frame, face)
                 cap.release()
                 cv2.destroyAllWindows()
                 return np.array(face_embedding)
             
             cv2.imshow("Capture Face", frame)
             if cv2.waitKey(1) & 0xFF == ord('q'):
                 break

         cap.release()
         cv2.destroyAllWindows()
     ```

   - Recognize the captured face:

     ```python
     def recognize_face(new_embedding, stored_embeddings):
         min_distance = float('inf')
         recognized_name = None
         for student_id, data in stored_embeddings.items():
             distance = cosine(new_embedding, data['embedding'])
             if distance < min_distance:
                 min_distance = distance
                 recognized_name = data['name']
         return recognized_name
     ```

   - Run the main script to capture and recognize the face:

     ```python
     stored_embeddings = get_embeddings_from_db()
     new_face_embedding = capture_face()
     recognized_name = recognize_face(new_face_embedding, stored_embeddings)
     if recognized_name:
         print(f"Recognized face as: {recognized_name}")
     else:
         print("Face not recognized")
     ```

5. Handling Challenges:
   - Challenges faced include:
     - Issues with Dlib installation.
     - Compatibility problems in Jupyter Notebook and Google Colab.
     - Adjusting the database schema to improve performance.
     - Handling misclassification due to similar facial features.
     - Future improvements could include using more sophisticated models like ArcFace or FaceNet.

6. Future Directions:
   - Address the misclassification issues by incorporating advanced models.
   - Explore cloud-based solutions for scalability.
   - Implement real-time monitoring and alert systems.
   - Integrate with other biometric systems for multi-factor authentication.

End of Steps.
